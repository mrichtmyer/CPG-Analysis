{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish connection to engine\n",
    "engine = create_engine(\"postgresql://postgres:postgres@localhost/CPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(table=\"eucerin_intensive_lotion\", \n",
    "         engine=create_engine(\"postgresql://postgres:postgres@localhost/CPG\")):\n",
    "    \n",
    "    # connect engine\n",
    "    conn = engine.connect()\n",
    "    \n",
    "    # try making query asked for\n",
    "    try:\n",
    "        query = f\"SELECT * FROM {table}\"\n",
    "        # attempt to read table queried\n",
    "        data = pd.read_sql(query,conn)\n",
    "    except:\n",
    "        # output default data\n",
    "        query = \"SELECT * FROM eucerin_intensive_lotion\"\n",
    "        data = pd.read_sql(query,conn)\n",
    "    \n",
    "    return data\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>profile_name</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review</th>\n",
       "      <th>helpful</th>\n",
       "      <th>form</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Emüêæ</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>This is the moisturizer I‚Äôve been searching forü§©</td>\n",
       "      <td>Reviewed in the United States on May 18, 2018</td>\n",
       "      <td>I feel a little awkward posting a picture of m...</td>\n",
       "      <td>743 people found this helpful</td>\n",
       "      <td>Cream</td>\n",
       "      <td>CeraVe</td>\n",
       "      <td>CeraVe Moisturizing Cream</td>\n",
       "      <td>https://www.amazon.com/CeraVe-Moisturizing-Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mounir Errami</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Highly recommend!</td>\n",
       "      <td>Reviewed in the United States on January 4, 2019</td>\n",
       "      <td>I am a doctor. Not a dermatologist though. In ...</td>\n",
       "      <td>397 people found this helpful</td>\n",
       "      <td>Cream</td>\n",
       "      <td>CeraVe</td>\n",
       "      <td>CeraVe Moisturizing Cream</td>\n",
       "      <td>https://www.amazon.com/CeraVe-Moisturizing-Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Laura K.</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Best moisturizer</td>\n",
       "      <td>Reviewed in the United States on April 30, 2018</td>\n",
       "      <td>I have extremely dry skin that's also acne pro...</td>\n",
       "      <td>252 people found this helpful</td>\n",
       "      <td>Cream</td>\n",
       "      <td>CeraVe</td>\n",
       "      <td>CeraVe Moisturizing Cream</td>\n",
       "      <td>https://www.amazon.com/CeraVe-Moisturizing-Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BCB</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Yaaaassss! Moisture is my face‚Äôs friend.</td>\n",
       "      <td>Reviewed in the United States on April 7, 2018</td>\n",
       "      <td>Let me set the scene that is my 35 year old fa...</td>\n",
       "      <td>195 people found this helpful</td>\n",
       "      <td>Cream</td>\n",
       "      <td>CeraVe</td>\n",
       "      <td>CeraVe Moisturizing Cream</td>\n",
       "      <td>https://www.amazon.com/CeraVe-Moisturizing-Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>erinlbyrd</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>If you have eczema this will change your life</td>\n",
       "      <td>Reviewed in the United States on December 30, ...</td>\n",
       "      <td>My daughter has severe eczema, one of the wors...</td>\n",
       "      <td>384 people found this helpful</td>\n",
       "      <td>Cream</td>\n",
       "      <td>CeraVe</td>\n",
       "      <td>CeraVe Moisturizing Cream</td>\n",
       "      <td>https://www.amazon.com/CeraVe-Moisturizing-Cre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   profile_name               stars  \\\n",
       "0   1            Emüêæ  5.0 out of 5 stars   \n",
       "1   2  Mounir Errami  5.0 out of 5 stars   \n",
       "2   3       Laura K.  5.0 out of 5 stars   \n",
       "3   4            BCB  5.0 out of 5 stars   \n",
       "4   5      erinlbyrd  5.0 out of 5 stars   \n",
       "\n",
       "                                              title  \\\n",
       "0  This is the moisturizer I‚Äôve been searching forü§©   \n",
       "1                                 Highly recommend!   \n",
       "2                                  Best moisturizer   \n",
       "3          Yaaaassss! Moisture is my face‚Äôs friend.   \n",
       "4     If you have eczema this will change your life   \n",
       "\n",
       "                                         review_date  \\\n",
       "0      Reviewed in the United States on May 18, 2018   \n",
       "1   Reviewed in the United States on January 4, 2019   \n",
       "2    Reviewed in the United States on April 30, 2018   \n",
       "3     Reviewed in the United States on April 7, 2018   \n",
       "4  Reviewed in the United States on December 30, ...   \n",
       "\n",
       "                                              review  \\\n",
       "0  I feel a little awkward posting a picture of m...   \n",
       "1  I am a doctor. Not a dermatologist though. In ...   \n",
       "2  I have extremely dry skin that's also acne pro...   \n",
       "3  Let me set the scene that is my 35 year old fa...   \n",
       "4  My daughter has severe eczema, one of the wors...   \n",
       "\n",
       "                         helpful   form   brand                        sku  \\\n",
       "0  743 people found this helpful  Cream  CeraVe  CeraVe Moisturizing Cream   \n",
       "1  397 people found this helpful  Cream  CeraVe  CeraVe Moisturizing Cream   \n",
       "2  252 people found this helpful  Cream  CeraVe  CeraVe Moisturizing Cream   \n",
       "3  195 people found this helpful  Cream  CeraVe  CeraVe Moisturizing Cream   \n",
       "4  384 people found this helpful  Cream  CeraVe  CeraVe Moisturizing Cream   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.amazon.com/CeraVe-Moisturizing-Cre...  \n",
       "1  https://www.amazon.com/CeraVe-Moisturizing-Cre...  \n",
       "2  https://www.amazon.com/CeraVe-Moisturizing-Cre...  \n",
       "3  https://www.amazon.com/CeraVe-Moisturizing-Cre...  \n",
       "4  https://www.amazon.com/CeraVe-Moisturizing-Cre...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = readData(table=\"CeraVe_cream\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractStars(row):\n",
    "    \"\"\"Lambda function to extract number of stars left in rating\"\"\"\n",
    "    return float(row.split(' ')[0]) \n",
    "\n",
    "def extractHelpful(row):\n",
    "    \"\"\"Lambda function to extract number of upvotes on Amazon\"\"\"\n",
    "    rev = row.split(' ')[0]\n",
    "    \n",
    "    if(rev.isnumeric()):\n",
    "        return int(rev)\n",
    "    elif(rev==\"one\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def extractDate(row):\n",
    "    \"\"\"Lambda function to convert string into datetime object\"\"\"\n",
    "    date = pd.to_datetime(row[33:])\n",
    "    return date\n",
    "\n",
    "def convertTime(rev):\n",
    "    \"\"\"Lambda function to abstract datetime object per month for groupby\"\"\"\n",
    "    corr_date = rev-pd.offsets.MonthBegin(1) \n",
    "    return corr_date\n",
    "\n",
    "def countWords(rev):\n",
    "    \"\"\"Lambda function to count all words in a particular review\"\"\"\n",
    "    return len(word_tokenize(rev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_transform(table=\"eucerin_intensive_lotion\",\n",
    "                   engine=create_engine(\"postgresql://postgres:postgres@localhost/CPG\")):\n",
    "    \"\"\"Docstring: makes query to PostgreSQL database using the table defined.\n",
    "    Performs all transformations, including cleaning prior to returning dataframe\"\"\"\n",
    "    \n",
    "    # read in raw data from PostgreSQL\n",
    "    data = readData(table,engine)\n",
    "       \n",
    "    # transformations\n",
    "    data[\"stars\"] = data.apply(lambda x: extractStars(x[\"stars\"]),axis=1)\n",
    "    data[\"helpful\"] = data.apply(lambda x: extractHelpful(x[\"helpful\"]),axis=1)\n",
    "    data[\"review_date\"] = data.apply(lambda x: extractDate(x[\"review_date\"]),axis=1)\n",
    "    data[\"corr_date\"] = data.apply(lambda x: convertTime(x[\"review_date\"]),axis=1)\n",
    "    data[\"word_count\"] = data.apply(lambda x: countWords(x[\"review\"]),axis=1)\n",
    "    \n",
    "    # perform groupby on month to get aggregate data\n",
    "    gb = data.groupby('corr_date')[\"stars\"].mean()\n",
    "    \n",
    "    # find review with maximum upvoted comments\n",
    "    idx = data[\"helpful\"].argmax()\n",
    "    max_upvoted_review = data[\"review\"][idx]\n",
    "    \n",
    "    # convert dates back to strings\n",
    "    #data['review_date']=data['review_date'].astype(str)\n",
    "    #data['corr_date']=data['corr_date'].astype(str)\n",
    "    \n",
    "    \n",
    "    # populate dictionary containing all data to pass back to route\n",
    "    ratings_dict = {}\n",
    "    ratings_dict[\"review_date\"] = list(data[\"review_date\"])\n",
    "    ratings_dict[\"gb_date\"] = gb.index.astype(str).tolist()\n",
    "    ratings_dict[\"avg_monthly_rating\"] = list(gb)\n",
    "    ratings_dict[\"histogram_rating_values\"] = np.histogram(data[\"stars\"], bins=[1,2,3,4,5,6])[0].tolist()\n",
    "    ratings_dict[\"histogram_rating_bins\"] = np.histogram(data[\"stars\"], bins=[1,2,3,4,5,6])[1].tolist()\n",
    "    ratings_dict[\"max_upvoted_review\"] = max_upvoted_review\n",
    "    \n",
    "    return data, ratings_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewrichtmyer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n"
     ]
    }
   ],
   "source": [
    "test_df, test_dict = read_transform(table=\"CeraVe_cream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>profile_name</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review</th>\n",
       "      <th>helpful</th>\n",
       "      <th>form</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku</th>\n",
       "      <th>url</th>\n",
       "      <th>corr_date</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Emüêæ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is the moisturizer I‚Äôve been searching forü§©</td>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>I feel a little awkward posting a picture of m...</td>\n",
       "      <td>743</td>\n",
       "      <td>Cream</td>\n",
       "      <td>CeraVe</td>\n",
       "      <td>CeraVe Moisturizing Cream</td>\n",
       "      <td>https://www.amazon.com/CeraVe-Moisturizing-Cre...</td>\n",
       "      <td>2018-05-01 00:00:00</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mounir Errami</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Highly recommend!</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>I am a doctor. Not a dermatologist though. In ...</td>\n",
       "      <td>397</td>\n",
       "      <td>Cream</td>\n",
       "      <td>CeraVe</td>\n",
       "      <td>CeraVe Moisturizing Cream</td>\n",
       "      <td>https://www.amazon.com/CeraVe-Moisturizing-Cre...</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Laura K.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best moisturizer</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>I have extremely dry skin that's also acne pro...</td>\n",
       "      <td>252</td>\n",
       "      <td>Cream</td>\n",
       "      <td>CeraVe</td>\n",
       "      <td>CeraVe Moisturizing Cream</td>\n",
       "      <td>https://www.amazon.com/CeraVe-Moisturizing-Cre...</td>\n",
       "      <td>2018-04-01 00:00:00</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BCB</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yaaaassss! Moisture is my face‚Äôs friend.</td>\n",
       "      <td>2018-04-07</td>\n",
       "      <td>Let me set the scene that is my 35 year old fa...</td>\n",
       "      <td>195</td>\n",
       "      <td>Cream</td>\n",
       "      <td>CeraVe</td>\n",
       "      <td>CeraVe Moisturizing Cream</td>\n",
       "      <td>https://www.amazon.com/CeraVe-Moisturizing-Cre...</td>\n",
       "      <td>2018-04-01 00:00:00</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>erinlbyrd</td>\n",
       "      <td>5.0</td>\n",
       "      <td>If you have eczema this will change your life</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>My daughter has severe eczema, one of the wors...</td>\n",
       "      <td>384</td>\n",
       "      <td>Cream</td>\n",
       "      <td>CeraVe</td>\n",
       "      <td>CeraVe Moisturizing Cream</td>\n",
       "      <td>https://www.amazon.com/CeraVe-Moisturizing-Cre...</td>\n",
       "      <td>2015-12-01 00:00:00</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   profile_name  stars                                             title  \\\n",
       "0   1            Emüêæ    5.0  This is the moisturizer I‚Äôve been searching forü§©   \n",
       "1   2  Mounir Errami    5.0                                 Highly recommend!   \n",
       "2   3       Laura K.    5.0                                  Best moisturizer   \n",
       "3   4            BCB    5.0          Yaaaassss! Moisture is my face‚Äôs friend.   \n",
       "4   5      erinlbyrd    5.0     If you have eczema this will change your life   \n",
       "\n",
       "  review_date                                             review  helpful  \\\n",
       "0  2018-05-18  I feel a little awkward posting a picture of m...      743   \n",
       "1  2019-01-04  I am a doctor. Not a dermatologist though. In ...      397   \n",
       "2  2018-04-30  I have extremely dry skin that's also acne pro...      252   \n",
       "3  2018-04-07  Let me set the scene that is my 35 year old fa...      195   \n",
       "4  2015-12-30  My daughter has severe eczema, one of the wors...      384   \n",
       "\n",
       "    form   brand                        sku  \\\n",
       "0  Cream  CeraVe  CeraVe Moisturizing Cream   \n",
       "1  Cream  CeraVe  CeraVe Moisturizing Cream   \n",
       "2  Cream  CeraVe  CeraVe Moisturizing Cream   \n",
       "3  Cream  CeraVe  CeraVe Moisturizing Cream   \n",
       "4  Cream  CeraVe  CeraVe Moisturizing Cream   \n",
       "\n",
       "                                                 url            corr_date  \\\n",
       "0  https://www.amazon.com/CeraVe-Moisturizing-Cre...  2018-05-01 00:00:00   \n",
       "1  https://www.amazon.com/CeraVe-Moisturizing-Cre...  2019-01-01 00:00:00   \n",
       "2  https://www.amazon.com/CeraVe-Moisturizing-Cre...  2018-04-01 00:00:00   \n",
       "3  https://www.amazon.com/CeraVe-Moisturizing-Cre...  2018-04-01 00:00:00   \n",
       "4  https://www.amazon.com/CeraVe-Moisturizing-Cre...  2015-12-01 00:00:00   \n",
       "\n",
       "   word_count  \n",
       "0         390  \n",
       "1         142  \n",
       "2          74  \n",
       "3         162  \n",
       "4         159  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3128 entries, 0 to 3127\n",
      "Data columns (total 13 columns):\n",
      "id              3128 non-null int64\n",
      "profile_name    3128 non-null object\n",
      "stars           3128 non-null float64\n",
      "title           3128 non-null object\n",
      "review_date     3128 non-null object\n",
      "review          3128 non-null object\n",
      "helpful         3128 non-null int64\n",
      "form            3128 non-null object\n",
      "brand           3128 non-null object\n",
      "sku             3128 non-null object\n",
      "url             3128 non-null object\n",
      "corr_date       3128 non-null object\n",
      "word_count      3128 non-null int64\n",
      "dtypes: float64(1), int64(3), object(9)\n",
      "memory usage: 317.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['review_date']=test_df['review_date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-05-18'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['review_date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_date': ['2018-05-18',\n",
       "  '2019-01-04',\n",
       "  '2018-04-30',\n",
       "  '2018-04-07',\n",
       "  '2015-12-30',\n",
       "  '2019-01-17',\n",
       "  '2018-05-30',\n",
       "  '2018-03-24',\n",
       "  '2019-05-09',\n",
       "  '2019-10-11',\n",
       "  '2019-06-04',\n",
       "  '2018-12-21',\n",
       "  '2019-01-14',\n",
       "  '2019-07-12',\n",
       "  '2019-04-11',\n",
       "  '2019-03-21',\n",
       "  '2019-04-30',\n",
       "  '2019-03-03',\n",
       "  '2018-10-30',\n",
       "  '2019-08-01',\n",
       "  '2019-02-14',\n",
       "  '2019-08-23',\n",
       "  '2018-11-07',\n",
       "  '2018-04-04',\n",
       "  '2019-04-05',\n",
       "  '2018-12-15',\n",
       "  '2018-12-29',\n",
       "  '2019-08-03',\n",
       "  '2018-07-27',\n",
       "  '2018-08-23',\n",
       "  '2019-06-01',\n",
       "  '2019-02-15',\n",
       "  '2019-02-27',\n",
       "  '2018-03-17',\n",
       "  '2018-12-07',\n",
       "  '2019-06-23',\n",
       "  '2019-04-16',\n",
       "  '2018-11-23',\n",
       "  '2019-01-07',\n",
       "  '2019-01-09',\n",
       "  '2018-08-28',\n",
       "  '2020-01-24',\n",
       "  '2019-11-06',\n",
       "  '2019-11-25',\n",
       "  '2020-02-24',\n",
       "  '2019-10-02',\n",
       "  '2019-08-15',\n",
       "  '2019-06-29',\n",
       "  '2019-02-24',\n",
       "  '2018-12-14',\n",
       "  '2018-06-18',\n",
       "  '2019-11-10',\n",
       "  '2018-06-07',\n",
       "  '2019-12-08',\n",
       "  '2018-09-09',\n",
       "  '2019-07-13',\n",
       "  '2019-03-17',\n",
       "  '2019-07-08',\n",
       "  '2019-12-18',\n",
       "  '2019-08-23',\n",
       "  '2019-01-13',\n",
       "  '2019-12-01',\n",
       "  '2019-03-20',\n",
       "  '2019-10-15',\n",
       "  '2019-08-28',\n",
       "  '2019-10-22',\n",
       "  '2020-03-06',\n",
       "  '2019-10-11',\n",
       "  '2019-10-10',\n",
       "  '2018-12-04',\n",
       "  '2018-09-13',\n",
       "  '2019-03-20',\n",
       "  '2020-01-18',\n",
       "  '2020-01-22',\n",
       "  '2019-07-14',\n",
       "  '2019-10-19',\n",
       "  '2019-06-09',\n",
       "  '2019-02-12',\n",
       "  '2019-07-30',\n",
       "  '2019-03-03',\n",
       "  '2019-12-29',\n",
       "  '2019-11-09',\n",
       "  '2019-12-28',\n",
       "  '2019-10-29',\n",
       "  '2019-05-13',\n",
       "  '2019-06-12',\n",
       "  '2020-01-05',\n",
       "  '2019-05-22',\n",
       "  '2019-10-28',\n",
       "  '2019-05-19',\n",
       "  '2019-07-18',\n",
       "  '2018-06-22',\n",
       "  '2019-04-06',\n",
       "  '2019-10-09',\n",
       "  '2019-03-04',\n",
       "  '2019-07-30',\n",
       "  '2019-07-27',\n",
       "  '2019-11-16',\n",
       "  '2019-03-09',\n",
       "  '2019-05-10',\n",
       "  '2019-08-14',\n",
       "  '2019-08-21',\n",
       "  '2018-11-25',\n",
       "  '2019-04-16',\n",
       "  '2019-11-28',\n",
       "  '2020-02-10',\n",
       "  '2019-05-02',\n",
       "  '2019-05-24',\n",
       "  '2020-01-05',\n",
       "  '2019-02-03',\n",
       "  '2019-07-20',\n",
       "  '2019-05-22',\n",
       "  '2019-11-07',\n",
       "  '2019-01-07',\n",
       "  '2019-08-01',\n",
       "  '2018-12-15',\n",
       "  '2019-08-22',\n",
       "  '2019-08-19',\n",
       "  '2019-02-12',\n",
       "  '2019-11-23',\n",
       "  '2019-11-09',\n",
       "  '2019-05-05',\n",
       "  '2019-12-17',\n",
       "  '2019-08-05',\n",
       "  '2020-03-22',\n",
       "  '2019-11-26',\n",
       "  '2019-01-16',\n",
       "  '2020-01-14',\n",
       "  '2020-03-13',\n",
       "  '2018-12-27',\n",
       "  '2020-02-01',\n",
       "  '2019-05-12',\n",
       "  '2019-07-16',\n",
       "  '2019-11-20',\n",
       "  '2019-02-27',\n",
       "  '2019-09-26',\n",
       "  '2019-06-24',\n",
       "  '2019-08-08',\n",
       "  '2020-01-15',\n",
       "  '2020-01-08',\n",
       "  '2019-09-01',\n",
       "  '2019-08-19',\n",
       "  '2019-07-05',\n",
       "  '2019-07-03',\n",
       "  '2020-02-20',\n",
       "  '2019-04-04',\n",
       "  '2019-03-09',\n",
       "  '2019-07-16',\n",
       "  '2019-03-14',\n",
       "  '2019-03-26',\n",
       "  '2020-02-12',\n",
       "  '2019-08-23',\n",
       "  '2019-01-03',\n",
       "  '2019-03-20',\n",
       "  '2019-05-29',\n",
       "  '2019-04-05',\n",
       "  '2020-02-23',\n",
       "  '2019-12-10',\n",
       "  '2020-02-06',\n",
       "  '2018-07-31',\n",
       "  '2019-05-23',\n",
       "  '2019-04-26',\n",
       "  '2020-02-22',\n",
       "  '2020-03-04',\n",
       "  '2019-06-11',\n",
       "  '2019-04-10',\n",
       "  '2019-11-23',\n",
       "  '2020-03-20',\n",
       "  '2019-06-23',\n",
       "  '2019-08-31',\n",
       "  '2019-08-22',\n",
       "  '2019-07-08',\n",
       "  '2019-06-12',\n",
       "  '2019-09-22',\n",
       "  '2019-07-24',\n",
       "  '2019-06-21',\n",
       "  '2019-08-26',\n",
       "  '2019-05-21',\n",
       "  '2018-09-14',\n",
       "  '2018-09-21',\n",
       "  '2020-03-17',\n",
       "  '2019-08-19',\n",
       "  '2019-11-25',\n",
       "  '2019-04-04',\n",
       "  '2019-09-19',\n",
       "  '2019-08-08',\n",
       "  '2019-01-15',\n",
       "  '2020-02-27',\n",
       "  '2020-02-28',\n",
       "  '2019-06-17',\n",
       "  '2020-01-10',\n",
       "  '2020-01-13',\n",
       "  '2020-03-01',\n",
       "  '2019-03-07',\n",
       "  '2019-01-07',\n",
       "  '2019-07-07',\n",
       "  '2020-03-06',\n",
       "  '2019-10-31',\n",
       "  '2019-04-30',\n",
       "  '2019-10-17',\n",
       "  '2019-03-27',\n",
       "  '2019-01-28',\n",
       "  '2019-10-22',\n",
       "  '2019-04-18',\n",
       "  '2020-01-23',\n",
       "  '2019-03-09',\n",
       "  '2019-07-07',\n",
       "  '2019-06-23',\n",
       "  '2019-05-03',\n",
       "  '2020-03-12',\n",
       "  '2020-03-12',\n",
       "  '2020-02-24',\n",
       "  '2019-04-04',\n",
       "  '2019-06-16',\n",
       "  '2018-11-05',\n",
       "  '2019-10-20',\n",
       "  '2018-08-27',\n",
       "  '2019-01-14',\n",
       "  '2018-08-04',\n",
       "  '2018-11-24',\n",
       "  '2018-12-08',\n",
       "  '2019-10-08',\n",
       "  '2018-12-24',\n",
       "  '2020-01-22',\n",
       "  '2019-12-05',\n",
       "  '2019-08-04',\n",
       "  '2019-05-04',\n",
       "  '2019-07-14',\n",
       "  '2019-03-06',\n",
       "  '2018-12-18',\n",
       "  '2019-06-06',\n",
       "  '2019-10-24',\n",
       "  '2019-10-16',\n",
       "  '2020-01-18',\n",
       "  '2019-04-30',\n",
       "  '2019-07-28',\n",
       "  '2020-03-06',\n",
       "  '2018-12-29',\n",
       "  '2019-11-27',\n",
       "  '2018-12-02',\n",
       "  '2019-12-20',\n",
       "  '2019-06-06',\n",
       "  '2020-02-04',\n",
       "  '2020-01-13',\n",
       "  '2019-11-30',\n",
       "  '2020-02-03',\n",
       "  '2019-05-10',\n",
       "  '2019-09-04',\n",
       "  '2020-01-25',\n",
       "  '2019-07-27',\n",
       "  '2019-03-23',\n",
       "  '2019-12-31',\n",
       "  '2019-09-14',\n",
       "  '2019-02-19',\n",
       "  '2020-02-01',\n",
       "  '2019-07-06',\n",
       "  '2019-10-05',\n",
       "  '2019-11-19',\n",
       "  '2020-01-13',\n",
       "  '2020-03-11',\n",
       "  '2019-08-18',\n",
       "  '2018-11-23',\n",
       "  '2019-09-18',\n",
       "  '2019-04-21',\n",
       "  '2019-10-28',\n",
       "  '2019-06-20',\n",
       "  '2019-01-10',\n",
       "  '2019-04-22',\n",
       "  '2019-06-26',\n",
       "  '2020-01-07',\n",
       "  '2019-07-18',\n",
       "  '2020-02-17',\n",
       "  '2019-02-16',\n",
       "  '2020-01-29',\n",
       "  '2019-01-30',\n",
       "  '2019-06-14',\n",
       "  '2020-02-29',\n",
       "  '2018-12-10',\n",
       "  '2020-01-21',\n",
       "  '2019-07-13',\n",
       "  '2019-04-08',\n",
       "  '2019-06-05',\n",
       "  '2015-05-23',\n",
       "  '2019-01-22',\n",
       "  '2019-08-26',\n",
       "  '2020-02-12',\n",
       "  '2020-02-22',\n",
       "  '2019-06-03',\n",
       "  '2019-08-13',\n",
       "  '2018-12-31',\n",
       "  '2019-12-16',\n",
       "  '2019-07-16',\n",
       "  '2019-07-25',\n",
       "  '2019-12-28',\n",
       "  '2019-10-07',\n",
       "  '2019-10-11',\n",
       "  '2019-07-20',\n",
       "  '2019-03-15',\n",
       "  '2019-11-21',\n",
       "  '2019-08-13',\n",
       "  '2019-04-06',\n",
       "  '2019-02-16',\n",
       "  '2019-04-18',\n",
       "  '2019-07-15',\n",
       "  '2019-02-28',\n",
       "  '2020-02-02',\n",
       "  '2020-03-12',\n",
       "  '2020-03-22',\n",
       "  '2019-07-31',\n",
       "  '2020-01-05',\n",
       "  '2019-11-11',\n",
       "  '2020-03-09',\n",
       "  '2019-07-30',\n",
       "  '2019-09-24',\n",
       "  '2020-02-24',\n",
       "  '2020-01-20',\n",
       "  '2019-04-28',\n",
       "  '2019-10-27',\n",
       "  '2019-09-17',\n",
       "  '2020-02-14',\n",
       "  '2019-05-26',\n",
       "  '2019-05-16',\n",
       "  '2019-08-29',\n",
       "  '2020-03-11',\n",
       "  '2020-02-03',\n",
       "  '2020-02-24',\n",
       "  '2019-10-06',\n",
       "  '2019-08-03',\n",
       "  '2020-02-27',\n",
       "  '2019-03-10',\n",
       "  '2019-06-03',\n",
       "  '2019-12-21',\n",
       "  '2019-11-19',\n",
       "  '2019-06-04',\n",
       "  '2019-07-22',\n",
       "  '2019-06-21',\n",
       "  '2020-03-10',\n",
       "  '2019-08-06',\n",
       "  '2019-01-01',\n",
       "  '2019-01-23',\n",
       "  '2020-03-06',\n",
       "  '2020-01-30',\n",
       "  '2019-03-25',\n",
       "  '2020-01-25',\n",
       "  '2018-12-07',\n",
       "  '2019-07-28',\n",
       "  '2020-01-26',\n",
       "  '2019-05-06',\n",
       "  '2019-09-06',\n",
       "  '2019-06-01',\n",
       "  '2019-09-11',\n",
       "  '2020-01-13',\n",
       "  '2019-06-30',\n",
       "  '2019-12-03',\n",
       "  '2020-02-16',\n",
       "  '2020-01-03',\n",
       "  '2019-10-16',\n",
       "  '2019-08-13',\n",
       "  '2020-02-10',\n",
       "  '2020-01-27',\n",
       "  '2019-12-29',\n",
       "  '2019-08-16',\n",
       "  '2019-11-27',\n",
       "  '2019-02-22',\n",
       "  '2019-07-17',\n",
       "  '2019-12-09',\n",
       "  '2018-04-20',\n",
       "  '2020-03-08',\n",
       "  '2019-10-06',\n",
       "  '2019-11-26',\n",
       "  '2019-09-29',\n",
       "  '2019-02-26',\n",
       "  '2019-12-13',\n",
       "  '2019-06-16',\n",
       "  '2019-04-12',\n",
       "  '2019-10-05',\n",
       "  '2019-04-10',\n",
       "  '2019-08-28',\n",
       "  '2019-04-21',\n",
       "  '2019-05-22',\n",
       "  '2019-06-01',\n",
       "  '2019-08-16',\n",
       "  '2018-04-25',\n",
       "  '2020-01-06',\n",
       "  '2020-02-07',\n",
       "  '2019-04-14',\n",
       "  '2019-09-18',\n",
       "  '2020-02-01',\n",
       "  '2019-12-19',\n",
       "  '2019-11-03',\n",
       "  '2019-02-01',\n",
       "  '2018-12-23',\n",
       "  '2018-07-13',\n",
       "  '2018-12-02',\n",
       "  '2018-04-30',\n",
       "  '2020-02-11',\n",
       "  '2019-03-08',\n",
       "  '2020-01-30',\n",
       "  '2020-01-23',\n",
       "  '2020-01-01',\n",
       "  '2019-04-11',\n",
       "  '2020-02-03',\n",
       "  '2020-02-16',\n",
       "  '2019-10-12',\n",
       "  '2019-06-21',\n",
       "  '2018-11-12',\n",
       "  '2019-10-17',\n",
       "  '2019-07-11',\n",
       "  '2019-07-03',\n",
       "  '2019-01-23',\n",
       "  '2019-10-29',\n",
       "  '2019-05-13',\n",
       "  '2020-02-01',\n",
       "  '2019-07-03',\n",
       "  '2020-03-21',\n",
       "  '2019-01-31',\n",
       "  '2019-12-26',\n",
       "  '2019-02-13',\n",
       "  '2019-07-26',\n",
       "  '2020-01-11',\n",
       "  '2018-05-21',\n",
       "  '2019-01-02',\n",
       "  '2020-01-06',\n",
       "  '2019-11-11',\n",
       "  '2020-03-05',\n",
       "  '2018-09-23',\n",
       "  '2019-07-15',\n",
       "  '2019-02-17',\n",
       "  '2019-06-17',\n",
       "  '2019-09-25',\n",
       "  '2019-12-22',\n",
       "  '2018-06-14',\n",
       "  '2018-12-13',\n",
       "  '2018-06-01',\n",
       "  '2019-12-13',\n",
       "  '2019-08-30',\n",
       "  '2019-06-01',\n",
       "  '2020-02-21',\n",
       "  '2019-07-19',\n",
       "  '2019-10-14',\n",
       "  '2019-06-12',\n",
       "  '2019-12-20',\n",
       "  '2019-06-14',\n",
       "  '2018-09-21',\n",
       "  '2019-01-02',\n",
       "  '2019-08-25',\n",
       "  '2018-10-24',\n",
       "  '2019-06-20',\n",
       "  '2019-01-21',\n",
       "  '2018-07-24',\n",
       "  '2019-02-20',\n",
       "  '2019-11-30',\n",
       "  '2019-10-13',\n",
       "  '2019-07-13',\n",
       "  '2020-02-02',\n",
       "  '2019-11-09',\n",
       "  '2019-01-12',\n",
       "  '2019-12-07',\n",
       "  '2019-12-28',\n",
       "  '2018-05-09',\n",
       "  '2018-08-17',\n",
       "  '2019-10-01',\n",
       "  '2019-09-14',\n",
       "  '2020-02-18',\n",
       "  '2019-05-16',\n",
       "  '2020-01-05',\n",
       "  '2019-12-10',\n",
       "  '2019-12-04',\n",
       "  '2019-11-10',\n",
       "  '2019-04-05',\n",
       "  '2018-12-05',\n",
       "  '2019-08-19',\n",
       "  '2019-09-29',\n",
       "  '2019-09-23',\n",
       "  '2019-04-16',\n",
       "  '2019-11-23',\n",
       "  '2020-03-07',\n",
       "  '2018-10-28',\n",
       "  '2019-12-06',\n",
       "  '2019-01-12',\n",
       "  '2020-03-15',\n",
       "  '2020-03-04',\n",
       "  '2019-07-03',\n",
       "  '2019-12-28',\n",
       "  '2020-02-23',\n",
       "  '2018-05-28',\n",
       "  '2019-05-17',\n",
       "  '2019-11-04',\n",
       "  '2019-09-29',\n",
       "  '2018-05-10',\n",
       "  '2018-07-15',\n",
       "  '2019-10-22',\n",
       "  '2018-12-10',\n",
       "  '2019-11-18',\n",
       "  '2019-11-09',\n",
       "  '2019-09-26',\n",
       "  '2020-02-14',\n",
       "  '2019-10-11',\n",
       "  '2020-01-11',\n",
       "  '2019-11-20',\n",
       "  '2019-07-18',\n",
       "  '2019-02-17',\n",
       "  '2019-12-17',\n",
       "  '2019-07-18',\n",
       "  '2018-12-03',\n",
       "  '2019-06-29',\n",
       "  '2019-12-07',\n",
       "  '2019-06-07',\n",
       "  '2019-12-14',\n",
       "  '2019-07-13',\n",
       "  '2019-07-07',\n",
       "  '2019-12-28',\n",
       "  '2019-04-24',\n",
       "  '2020-02-07',\n",
       "  '2019-08-26',\n",
       "  '2019-06-19',\n",
       "  '2019-12-01',\n",
       "  '2020-01-14',\n",
       "  '2018-11-12',\n",
       "  '2019-04-23',\n",
       "  '2020-01-27',\n",
       "  '2019-07-02',\n",
       "  '2019-10-18',\n",
       "  '2020-02-27',\n",
       "  '2019-03-16',\n",
       "  '2019-06-23',\n",
       "  '2020-01-08',\n",
       "  '2019-06-03',\n",
       "  '2020-02-26',\n",
       "  '2019-05-26',\n",
       "  '2019-10-23',\n",
       "  '2018-06-13',\n",
       "  '2019-03-10',\n",
       "  '2019-07-18',\n",
       "  '2019-01-13',\n",
       "  '2019-09-12',\n",
       "  '2019-05-16',\n",
       "  '2019-11-07',\n",
       "  '2019-04-05',\n",
       "  '2018-03-13',\n",
       "  '2020-02-15',\n",
       "  '2019-05-09',\n",
       "  '2019-07-11',\n",
       "  '2019-07-31',\n",
       "  '2019-07-07',\n",
       "  '2019-02-28',\n",
       "  '2019-02-28',\n",
       "  '2019-08-09',\n",
       "  '2019-08-17',\n",
       "  '2019-11-18',\n",
       "  '2019-07-14',\n",
       "  '2019-04-28',\n",
       "  '2019-02-17',\n",
       "  '2019-08-15',\n",
       "  '2019-12-27',\n",
       "  '2019-04-16',\n",
       "  '2020-03-17',\n",
       "  '2019-08-10',\n",
       "  '2019-05-30',\n",
       "  '2019-09-25',\n",
       "  '2019-05-13',\n",
       "  '2019-12-08',\n",
       "  '2020-01-16',\n",
       "  '2019-07-09',\n",
       "  '2019-12-20',\n",
       "  '2019-10-31',\n",
       "  '2019-11-07',\n",
       "  '2020-03-11',\n",
       "  '2019-02-19',\n",
       "  '2019-04-28',\n",
       "  '2020-03-14',\n",
       "  '2019-08-05',\n",
       "  '2020-01-28',\n",
       "  '2019-03-19',\n",
       "  '2019-07-14',\n",
       "  '2020-01-21',\n",
       "  '2020-02-18',\n",
       "  '2019-02-17',\n",
       "  '2019-02-27',\n",
       "  '2019-08-27',\n",
       "  '2019-06-13',\n",
       "  '2019-03-03',\n",
       "  '2019-07-14',\n",
       "  '2019-01-05',\n",
       "  '2019-03-07',\n",
       "  '2018-09-03',\n",
       "  '2019-01-17',\n",
       "  '2019-10-30',\n",
       "  '2019-02-19',\n",
       "  '2019-03-11',\n",
       "  '2019-12-05',\n",
       "  '2020-01-04',\n",
       "  '2019-02-05',\n",
       "  '2019-11-10',\n",
       "  '2019-11-24',\n",
       "  '2019-12-16',\n",
       "  '2019-01-01',\n",
       "  '2019-08-20',\n",
       "  '2020-02-28',\n",
       "  '2020-01-19',\n",
       "  '2019-03-06',\n",
       "  '2019-04-29',\n",
       "  '2018-12-10',\n",
       "  '2019-10-06',\n",
       "  '2018-11-06',\n",
       "  '2018-11-19',\n",
       "  '2019-03-13',\n",
       "  '2019-06-20',\n",
       "  '2019-07-27',\n",
       "  '2019-03-09',\n",
       "  '2019-07-12',\n",
       "  '2018-12-30',\n",
       "  '2019-08-18',\n",
       "  '2020-01-07',\n",
       "  '2020-01-29',\n",
       "  '2019-05-03',\n",
       "  '2019-11-07',\n",
       "  '2020-01-06',\n",
       "  '2019-06-15',\n",
       "  '2019-09-09',\n",
       "  '2020-01-26',\n",
       "  '2019-12-21',\n",
       "  '2019-01-01',\n",
       "  '2019-09-05',\n",
       "  '2019-08-17',\n",
       "  '2020-02-19',\n",
       "  '2019-03-08',\n",
       "  '2019-08-29',\n",
       "  '2019-08-27',\n",
       "  '2020-01-31',\n",
       "  '2020-03-21',\n",
       "  '2019-11-14',\n",
       "  '2020-02-22',\n",
       "  '2019-12-19',\n",
       "  '2019-12-08',\n",
       "  '2018-10-25',\n",
       "  '2019-04-04',\n",
       "  '2019-12-12',\n",
       "  '2019-11-21',\n",
       "  '2020-03-23',\n",
       "  '2020-02-06',\n",
       "  '2020-02-16',\n",
       "  '2019-04-04',\n",
       "  '2019-03-15',\n",
       "  '2019-11-01',\n",
       "  '2020-02-03',\n",
       "  '2020-02-08',\n",
       "  '2019-05-15',\n",
       "  '2020-02-12',\n",
       "  '2019-08-14',\n",
       "  '2019-12-21',\n",
       "  '2019-07-11',\n",
       "  '2018-05-28',\n",
       "  '2019-02-08',\n",
       "  '2019-10-07',\n",
       "  '2018-12-05',\n",
       "  '2019-10-18',\n",
       "  '2019-07-05',\n",
       "  '2019-03-23',\n",
       "  '2019-07-19',\n",
       "  '2019-05-07',\n",
       "  '2020-02-18',\n",
       "  '2020-01-25',\n",
       "  '2019-12-18',\n",
       "  '2018-11-12',\n",
       "  '2019-08-09',\n",
       "  '2019-06-27',\n",
       "  '2018-10-08',\n",
       "  '2018-10-15',\n",
       "  '2020-03-07',\n",
       "  '2020-02-07',\n",
       "  '2020-03-11',\n",
       "  '2019-07-21',\n",
       "  '2019-07-15',\n",
       "  '2019-07-12',\n",
       "  '2020-01-12',\n",
       "  '2019-09-05',\n",
       "  '2019-08-31',\n",
       "  '2019-02-27',\n",
       "  '2019-06-16',\n",
       "  '2020-01-28',\n",
       "  '2019-04-18',\n",
       "  '2019-06-05',\n",
       "  '2020-01-21',\n",
       "  '2019-09-13',\n",
       "  '2019-08-08',\n",
       "  '2019-07-31',\n",
       "  '2020-01-16',\n",
       "  '2019-09-09',\n",
       "  '2019-12-13',\n",
       "  '2019-09-05',\n",
       "  '2018-12-23',\n",
       "  '2020-02-03',\n",
       "  '2019-11-26',\n",
       "  '2019-01-04',\n",
       "  '2019-11-05',\n",
       "  '2018-07-16',\n",
       "  '2019-11-13',\n",
       "  '2020-02-04',\n",
       "  '2019-12-17',\n",
       "  '2019-12-14',\n",
       "  '2020-01-08',\n",
       "  '2019-09-11',\n",
       "  '2018-08-31',\n",
       "  '2020-01-13',\n",
       "  '2020-03-12',\n",
       "  '2019-12-28',\n",
       "  '2019-11-27',\n",
       "  '2019-02-23',\n",
       "  '2019-08-20',\n",
       "  '2019-10-27',\n",
       "  '2018-08-20',\n",
       "  '2019-06-23',\n",
       "  '2019-04-24',\n",
       "  '2019-06-03',\n",
       "  '2019-05-29',\n",
       "  '2019-06-21',\n",
       "  '2019-08-29',\n",
       "  '2019-10-31',\n",
       "  '2019-04-02',\n",
       "  '2019-08-12',\n",
       "  '2019-04-20',\n",
       "  '2020-01-30',\n",
       "  '2019-12-13',\n",
       "  '2019-04-24',\n",
       "  '2019-04-16',\n",
       "  '2020-01-17',\n",
       "  '2016-05-22',\n",
       "  '2019-08-24',\n",
       "  '2019-12-20',\n",
       "  '2019-01-19',\n",
       "  '2019-02-16',\n",
       "  '2019-08-31',\n",
       "  '2019-12-26',\n",
       "  '2020-01-11',\n",
       "  '2019-08-25',\n",
       "  '2019-06-08',\n",
       "  '2019-02-06',\n",
       "  '2019-05-19',\n",
       "  '2018-12-07',\n",
       "  '2019-01-18',\n",
       "  '2019-08-13',\n",
       "  '2019-05-22',\n",
       "  '2019-07-18',\n",
       "  '2019-04-25',\n",
       "  '2019-02-06',\n",
       "  '2019-01-06',\n",
       "  '2020-01-23',\n",
       "  '2018-07-11',\n",
       "  '2020-02-10',\n",
       "  '2019-12-22',\n",
       "  '2019-12-13',\n",
       "  '2018-05-11',\n",
       "  '2019-11-01',\n",
       "  '2019-01-01',\n",
       "  '2019-02-02',\n",
       "  '2020-02-25',\n",
       "  '2018-03-15',\n",
       "  '2020-02-14',\n",
       "  '2020-01-02',\n",
       "  '2020-01-10',\n",
       "  '2019-06-01',\n",
       "  '2019-03-23',\n",
       "  '2019-09-16',\n",
       "  '2019-04-02',\n",
       "  '2020-01-10',\n",
       "  '2020-01-08',\n",
       "  '2020-02-25',\n",
       "  '2019-10-04',\n",
       "  '2019-12-26',\n",
       "  '2019-11-12',\n",
       "  '2020-01-27',\n",
       "  '2019-06-28',\n",
       "  '2019-05-02',\n",
       "  '2019-11-14',\n",
       "  '2019-10-17',\n",
       "  '2019-09-09',\n",
       "  '2019-11-05',\n",
       "  '2020-02-22',\n",
       "  '2020-02-07',\n",
       "  '2020-03-08',\n",
       "  '2019-07-06',\n",
       "  '2019-05-22',\n",
       "  '2019-12-05',\n",
       "  '2020-01-03',\n",
       "  '2019-06-13',\n",
       "  '2019-07-12',\n",
       "  '2019-04-20',\n",
       "  '2019-08-10',\n",
       "  '2019-11-26',\n",
       "  '2018-08-27',\n",
       "  '2020-02-08',\n",
       "  '2019-09-25',\n",
       "  '2019-05-03',\n",
       "  '2020-01-11',\n",
       "  '2019-07-07',\n",
       "  '2019-09-12',\n",
       "  '2019-06-05',\n",
       "  '2018-12-02',\n",
       "  '2019-02-15',\n",
       "  '2018-04-18',\n",
       "  '2019-06-18',\n",
       "  '2020-03-06',\n",
       "  '2020-01-18',\n",
       "  '2019-12-11',\n",
       "  '2019-06-22',\n",
       "  '2019-04-09',\n",
       "  '2019-11-20',\n",
       "  '2020-02-20',\n",
       "  '2019-04-16',\n",
       "  '2020-01-30',\n",
       "  '2019-10-07',\n",
       "  '2019-09-02',\n",
       "  '2019-03-31',\n",
       "  '2020-01-05',\n",
       "  '2019-07-17',\n",
       "  '2019-11-20',\n",
       "  '2019-04-05',\n",
       "  '2019-09-27',\n",
       "  '2019-12-31',\n",
       "  '2019-12-27',\n",
       "  '2019-09-15',\n",
       "  '2018-12-25',\n",
       "  '2019-06-18',\n",
       "  '2019-10-13',\n",
       "  '2020-01-16',\n",
       "  '2019-06-01',\n",
       "  '2019-06-06',\n",
       "  '2019-09-10',\n",
       "  '2018-07-12',\n",
       "  '2019-07-06',\n",
       "  '2019-11-04',\n",
       "  '2019-08-23',\n",
       "  '2018-05-27',\n",
       "  '2019-03-13',\n",
       "  '2019-06-18',\n",
       "  '2019-10-11',\n",
       "  '2019-11-12',\n",
       "  '2019-03-15',\n",
       "  '2019-08-08',\n",
       "  '2019-12-19',\n",
       "  '2018-06-19',\n",
       "  '2019-11-23',\n",
       "  '2019-05-13',\n",
       "  '2019-12-28',\n",
       "  '2019-06-08',\n",
       "  '2019-04-17',\n",
       "  '2019-01-13',\n",
       "  '2020-01-09',\n",
       "  '2018-07-09',\n",
       "  '2019-03-04',\n",
       "  '2019-02-19',\n",
       "  '2020-02-19',\n",
       "  '2019-11-16',\n",
       "  '2019-08-21',\n",
       "  '2019-09-06',\n",
       "  '2019-08-08',\n",
       "  '2019-04-02',\n",
       "  '2020-01-31',\n",
       "  '2019-05-30',\n",
       "  '2019-04-09',\n",
       "  '2019-03-02',\n",
       "  '2018-12-08',\n",
       "  '2019-04-04',\n",
       "  '2019-11-22',\n",
       "  '2019-02-02',\n",
       "  '2019-04-16',\n",
       "  '2019-02-27',\n",
       "  '2020-03-10',\n",
       "  '2018-08-06',\n",
       "  '2019-02-28',\n",
       "  '2019-07-31',\n",
       "  '2019-11-27',\n",
       "  '2019-09-17',\n",
       "  '2019-02-26',\n",
       "  '2018-12-16',\n",
       "  '2019-07-31',\n",
       "  '2019-09-17',\n",
       "  '2020-01-23',\n",
       "  '2020-01-23',\n",
       "  '2019-12-10',\n",
       "  '2019-01-13',\n",
       "  '2020-02-05',\n",
       "  '2020-01-13',\n",
       "  '2019-09-22',\n",
       "  '2019-04-26',\n",
       "  '2020-02-18',\n",
       "  '2019-03-27',\n",
       "  '2020-03-21',\n",
       "  '2019-01-01',\n",
       "  '2019-10-08',\n",
       "  '2019-03-15',\n",
       "  '2019-07-17',\n",
       "  '2019-12-24',\n",
       "  '2018-11-26',\n",
       "  '2020-03-21',\n",
       "  '2019-12-10',\n",
       "  '2019-02-12',\n",
       "  '2019-10-12',\n",
       "  '2019-02-13',\n",
       "  '2019-01-03',\n",
       "  '2020-01-09',\n",
       "  '2019-11-25',\n",
       "  '2020-01-12',\n",
       "  '2019-09-05',\n",
       "  '2020-02-14',\n",
       "  '2020-01-26',\n",
       "  '2019-12-15',\n",
       "  '2019-02-15',\n",
       "  '2020-01-30',\n",
       "  '2020-03-12',\n",
       "  '2019-12-02',\n",
       "  '2019-09-24',\n",
       "  '2020-02-09',\n",
       "  '2020-02-17',\n",
       "  '2018-07-29',\n",
       "  '2019-12-24',\n",
       "  '2019-10-08',\n",
       "  '2019-10-03',\n",
       "  '2019-06-06',\n",
       "  '2020-02-09',\n",
       "  '2019-11-02',\n",
       "  '2019-07-31',\n",
       "  '2019-12-30',\n",
       "  '2018-12-10',\n",
       "  '2019-10-25',\n",
       "  '2019-06-25',\n",
       "  '2020-03-20',\n",
       "  '2020-03-05',\n",
       "  '2019-04-20',\n",
       "  '2019-11-21',\n",
       "  '2019-08-15',\n",
       "  '2019-06-16',\n",
       "  '2019-01-17',\n",
       "  '2019-12-23',\n",
       "  '2019-03-13',\n",
       "  '2018-06-11',\n",
       "  '2018-12-20',\n",
       "  '2018-09-01',\n",
       "  '2020-02-11',\n",
       "  '2018-08-16',\n",
       "  '2018-09-24',\n",
       "  '2019-12-06',\n",
       "  '2019-03-07',\n",
       "  '2020-01-15',\n",
       "  '2020-03-10',\n",
       "  '2019-12-11',\n",
       "  '2019-11-26',\n",
       "  '2019-09-20',\n",
       "  '2019-02-28',\n",
       "  '2019-09-30',\n",
       "  '2020-02-29',\n",
       "  '2019-04-23',\n",
       "  '2018-05-03',\n",
       "  '2019-05-22',\n",
       "  '2019-10-24',\n",
       "  '2020-01-25',\n",
       "  '2019-11-07',\n",
       "  '2018-12-16',\n",
       "  '2019-08-13',\n",
       "  '2019-08-05',\n",
       "  '2019-11-12',\n",
       "  '2018-06-17',\n",
       "  '2019-02-19',\n",
       "  '2019-04-09',\n",
       "  '2020-03-01',\n",
       "  '2019-05-08',\n",
       "  '2019-05-28',\n",
       "  '2019-01-06',\n",
       "  '2019-06-28',\n",
       "  '2019-01-22',\n",
       "  '2019-09-08',\n",
       "  '2019-11-04',\n",
       "  '2019-03-04',\n",
       "  '2018-08-15',\n",
       "  '2019-08-04',\n",
       "  '2019-06-14',\n",
       "  '2018-11-01',\n",
       "  '2018-11-05',\n",
       "  '2018-06-13',\n",
       "  '2019-08-23',\n",
       "  '2019-11-08',\n",
       "  '2019-12-30',\n",
       "  '2019-01-09',\n",
       "  '2019-11-14',\n",
       "  '2019-05-23',\n",
       "  '2019-12-14',\n",
       "  '2019-12-15',\n",
       "  '2019-06-28',\n",
       "  '2018-11-16',\n",
       "  '2020-02-28',\n",
       "  '2019-12-19',\n",
       "  '2019-05-31',\n",
       "  '2019-08-15',\n",
       "  '2019-05-23',\n",
       "  '2019-08-21',\n",
       "  '2019-05-02',\n",
       "  '2019-06-29',\n",
       "  '2020-02-08',\n",
       "  '2018-05-28',\n",
       "  ...],\n",
       " 'gb_date': ['2015-05-01',\n",
       "  '2015-07-01',\n",
       "  '2015-08-01',\n",
       "  '2015-09-01',\n",
       "  '2015-10-01',\n",
       "  '2015-11-01',\n",
       "  '2015-12-01',\n",
       "  '2016-01-01',\n",
       "  '2016-05-01',\n",
       "  '2016-07-01',\n",
       "  '2016-08-01',\n",
       "  '2016-09-01',\n",
       "  '2017-03-01',\n",
       "  '2017-09-01',\n",
       "  '2018-02-01',\n",
       "  '2018-03-01',\n",
       "  '2018-04-01',\n",
       "  '2018-05-01',\n",
       "  '2018-06-01',\n",
       "  '2018-07-01',\n",
       "  '2018-08-01',\n",
       "  '2018-09-01',\n",
       "  '2018-10-01',\n",
       "  '2018-11-01',\n",
       "  '2018-12-01',\n",
       "  '2019-01-01',\n",
       "  '2019-02-01',\n",
       "  '2019-03-01',\n",
       "  '2019-04-01',\n",
       "  '2019-05-01',\n",
       "  '2019-06-01',\n",
       "  '2019-07-01',\n",
       "  '2019-08-01',\n",
       "  '2019-09-01',\n",
       "  '2019-10-01',\n",
       "  '2019-11-01',\n",
       "  '2019-12-01',\n",
       "  '2020-01-01',\n",
       "  '2020-02-01',\n",
       "  '2020-03-01'],\n",
       " 'avg_monthly_rating': [5.0,\n",
       "  5.0,\n",
       "  5.0,\n",
       "  5.0,\n",
       "  5.0,\n",
       "  4.75,\n",
       "  5.0,\n",
       "  5.0,\n",
       "  5.0,\n",
       "  5.0,\n",
       "  3.0,\n",
       "  5.0,\n",
       "  5.0,\n",
       "  5.0,\n",
       "  5.0,\n",
       "  4.0,\n",
       "  4.636363636363637,\n",
       "  4.814814814814815,\n",
       "  4.689655172413793,\n",
       "  4.6231884057971016,\n",
       "  4.645833333333333,\n",
       "  4.282051282051282,\n",
       "  4.5777777777777775,\n",
       "  4.533333333333333,\n",
       "  4.7226277372262775,\n",
       "  4.660256410256411,\n",
       "  4.553030303030303,\n",
       "  4.5136612021857925,\n",
       "  4.617283950617284,\n",
       "  4.613095238095238,\n",
       "  4.820224719101123,\n",
       "  4.666666666666667,\n",
       "  4.796296296296297,\n",
       "  4.657894736842105,\n",
       "  4.659574468085107,\n",
       "  4.63125,\n",
       "  4.7312252964426875,\n",
       "  4.746987951807229,\n",
       "  4.744047619047619,\n",
       "  4.5473684210526315],\n",
       " 'histogram_rating_values': [128, 57, 94, 175, 2674],\n",
       " 'histogram_rating_bins': [1, 2, 3, 4, 5, 6],\n",
       " 'max_upvoted_review': 'I feel a little awkward posting a picture of myself after spending the day in hot and humid 75degree weather, mowing, gardening, and having a busy day of taking care of my grandfather... But, because I rely on people‚Äôs reviews, I have to give credit when credit is due...‚ù§Ô∏èI LOVE THIS MOISTURIZER‚ù§Ô∏èI‚Äôve NEVER been able to find a lotion that can moisturize my skin without it looking greasy, or a  ‚Äúnon greasy‚Äù lotion that I have to apply 1000 times a day..üî∏I have severely sundamaged skinüî∏I have deep visible poresüî∏I have very oily and very ‚Äúshiny‚Äù skinüî∏I have acne prone skinüî∏I have patches around my nose and eyelids that are always dryI HAVE SOME AWFUL SKIN and yea it sucks!üîπThis moisturizer has made my face feel so soft, gives it a GLOWüîπthe amount I use is 2-4 finger tips of moisturizer on my face after I wake up and before I go to sleepüåüFor those who want to know my skin care routine:üí•1st I clean my face with 2% Salicylic Acid acne washüí•2nd I use witch hazel for a toner to remove any left over residue (instead of astringent)üí•3rd I make my own sugar scrubs (they are random concoctions usually consisting of raw honey, aloe Vera jel, sugar, fresh squeezed ginger from a garlic squisher, baking soda, and/or oatmeal)üí•4th twice a week I use bentonite clay for a mask mixed with raw apple cider vinegar, honey, and activated charcoalüí•5th again use witch hazel toner to remove any clay residueüí•6th I use Vitamin C and hyaluronic acid serum for hydrationüí•7th I apply this moisturizerüí•8th I put rosehip or jojoba oil and tamanu oil over the moisturizerIt SOUNDS like a pain in the butt and a long process but it‚Äôs not!üåüI started using this lotion early May 2018 and it is now May 19, 2018 and I already see a differenceüåüI would definitely recommend CeraVe, seeing as how I‚Äôve been disappointed with so many products in the past and this is the 1st time in my life I‚Äôve ever seen my skin‚Äôs appearance improve'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3128 entries, 0 to 3127\n",
      "Data columns (total 13 columns):\n",
      "id              3128 non-null int64\n",
      "profile_name    3128 non-null object\n",
      "stars           3128 non-null float64\n",
      "title           3128 non-null object\n",
      "review_date     3128 non-null object\n",
      "review          3128 non-null object\n",
      "helpful         3128 non-null int64\n",
      "form            3128 non-null object\n",
      "brand           3128 non-null object\n",
      "sku             3128 non-null object\n",
      "url             3128 non-null object\n",
      "corr_date       3128 non-null datetime64[ns]\n",
      "word_count      3128 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(8)\n",
      "memory usage: 317.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://sentiment.nrc.ca/lexicons-for-research/\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def text_emotion(table=\"eucerin_intensive_lotion\",\n",
    "                   engine=create_engine(\"postgresql://postgres:postgres@localhost/CPG\")):\n",
    "    \n",
    "    test_df, test_dict = read_transform()\n",
    "    \n",
    "    new_df = test_df.copy() # can refactor later, but this will be consistent with naming convention\n",
    "    \n",
    "    column = \"review\"\n",
    "\n",
    "    \n",
    "    filepath = ('data/NRC-Sentiment-Emotion-Lexicons/NRC-Emotion-Lexicon-v0.92/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt')  \n",
    "    \n",
    "    emolex_df = pd.read_csv(filepath, names=[\"word\", \"emotion\", \"association\"], sep='\\t')\n",
    "    emolex_words = emolex_df.pivot(index='word',\n",
    "                                   columns='emotion',\n",
    "                                   values='association').reset_index()\n",
    "    emotions = emolex_words.columns.drop('word')\n",
    "    \n",
    "    emo_df = pd.DataFrame(0,index=new_df.index, columns=emotions)\n",
    "    \n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    for i in range(0, len(new_df)):\n",
    "        row = new_df[column][i]\n",
    "        document = word_tokenize(row)\n",
    "        \n",
    "        for word in document:\n",
    "            word = stemmer.stem(word.lower())\n",
    "            \n",
    "            emo_score = emolex_words[emolex_words.word == word]\n",
    "            \n",
    "            if not emo_score.empty:\n",
    "                for emotion in list(emotions):\n",
    "                    emo_df.at[i,emotion] += emo_score[emotion]\n",
    "        new_df = pd.concat([new_df, emo_df], axis=1)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def monthlyEmotionAvg(filename,table=\"eucerin_intensive_lotion\",\n",
    "                   engine=create_engine(\"postgresql://postgres:postgres@localhost/CPG\")):\n",
    "\n",
    "    \n",
    "    # calculate emotional response\n",
    "    emotion_df = text_emotion(table,engine)\n",
    "    \n",
    "    # calculate date\n",
    "    #df['YearMonth'] = df['review_date'] - pd.offsets.MonthBegin(1)\n",
    "    date = list(emotion_df[\"corr_date\"]) ## HAVE TO HAVE THIS FCN\n",
    "    \n",
    "    # take row sums\n",
    "    emotion_df[\"anger_sum\"] = emotion_df[\"anger\"].sum(axis=1)/len(emotion_df[\"review\"])\n",
    "    emotion_df[\"anticipation_sum\"] = emotion_df[\"anticipation\"].sum(axis=1)/len(emotion_df[\"review\"])\n",
    "    emotion_df[\"disgust_sum\"] = emotion_df[\"disgust\"].sum(axis=1)/len(emotion_df[\"review\"])\n",
    "    emotion_df[\"fear_sum\"] = emotion_df[\"fear\"].sum(axis=1)/len(emotion_df[\"review\"])\n",
    "    emotion_df[\"joy_sum\"] = emotion_df[\"joy\"].sum(axis=1)/len(emotion_df[\"review\"])\n",
    "    emotion_df[\"negative_sum\"] = emotion_df[\"negative\"].sum(axis=1)/len(emotion_df[\"review\"])\n",
    "    emotion_df[\"positive_sum\"] = emotion_df[\"positive\"].sum(axis=1)/len(emotion_df[\"review\"])\n",
    "    emotion_df[\"sadness_sum\"] = emotion_df[\"sadness\"].sum(axis=1)/len(emotion_df[\"review\"])\n",
    "    emotion_df[\"surprise_sum\"] = emotion_df[\"surprise\"].sum(axis=1)/len(emotion_df[\"review\"])\n",
    "    emotion_df[\"trust_sum\"] = emotion_df[\"trust\"].sum(axis=1)/len(emotion_df[\"review\"])\n",
    "    \n",
    "    # take just sums\n",
    "    emotion_df = emotion_df.iloc[:,-10:]\n",
    "    \n",
    "    # store emotional response for all 10 vectors in dictionary\n",
    "    month_avg = {}\n",
    "    for col in emotion_df.columns:\n",
    "        emotions = list(emotion_df[col])\n",
    "        col_name = col[:-4]\n",
    "        month_avg[col_name] = list(pd.DataFrame({\"Date\": date, \"Emotion\": emotions}).groupby(\"Date\").mean()[\"Emotion\"])#.plot(kind=\"line\")\n",
    "    \n",
    "      \n",
    "    gb_dates = pd.DataFrame({\"Date\": date, \"Emotion\": emotions}).groupby(\"Date\").mean().index.astype(str).tolist()\n",
    "    month_avg[\"dates\"] = gb_dates\n",
    "    month_avg = pd.DataFrame(month_avg)\n",
    "                      \n",
    "    # format csv output\n",
    "    name = \"/Users/matthewrichtmyer/Documents/Data Science Bootcamp/Project 2/CPG-Analysis/data/emotion_csv/\" + str(filename)\n",
    "    month_avg.to_csv(name,index=False)\n",
    "    \n",
    "    return month_avg # this is just returning a dictionary, not list of dictionary which is needed for JS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewrichtmyer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n"
     ]
    }
   ],
   "source": [
    "# run model and save to csv for all tables in postgreSQL database\n",
    "month_avg = monthlyEmotionAvg(filename=\"CeraVe_cream.csv\",table=\"CeraVe_cream\",\n",
    "                             engine=create_engine(\"postgresql://postgres:postgres@localhost/CPG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewrichtmyer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-32b3a15300d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run model and save to csv for all tables in postgreSQL database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m month_avg = monthlyEmotionAvg(filename=\"cerave_cream.csv\",table=\"cerave_cream.csv\",\n\u001b[0;32m----> 3\u001b[0;31m                              engine=create_engine(\"postgresql://postgres:postgres@localhost/CPG\"))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-5d641b0305c0>\u001b[0m in \u001b[0;36mmonthlyEmotionAvg\u001b[0;34m(filename, table, engine)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# calculate emotional response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0memotion_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# calculate date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5d641b0305c0>\u001b[0m in \u001b[0;36mtext_emotion\u001b[0;34m(table, engine)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0memo_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memolex_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memolex_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0memo_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m         elif (is_extension_array_dtype(self) or\n\u001b[0;32m-> 1728\u001b[0;31m               (is_extension_array_dtype(other) and not is_scalar(other))):\n\u001b[0m\u001b[1;32m   1729\u001b[0m             \u001b[0;31m# Note: the `not is_scalar(other)` condition rules out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0;31m# e.g. other == \"category\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1747\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m     return (isinstance(dtype, ExtensionDtype) or\n\u001b[0;32m-> 1749\u001b[0;31m             registry.find(dtype) is not None)\n\u001b[0m\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdtype_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdtype_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36mconstruct_from_string\u001b[0;34m(cls, string)\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDateOffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         if (isinstance(string, compat.string_types) and\n\u001b[0m\u001b[1;32m    795\u001b[0m             (string.startswith('period[') or\n\u001b[1;32m    796\u001b[0m              string.startswith('Period[')) or\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run model and save to csv for all tables in postgreSQL database\n",
    "month_avg = monthlyEmotionAvg(filename=\"cerave_cream.csv\",table=\"cerave_cream\",\n",
    "                             engine=create_engine(\"postgresql://postgres:postgres@localhost/CPG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewrichtmyer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n"
     ]
    }
   ],
   "source": [
    "# run model and save to csv for all tables in postgreSQL database\n",
    "month_avg = monthlyEmotionAvg(filename=\"eucerin_adv_cream.csv\",table=\"eucerin_adv_cream\",\n",
    "                             engine=create_engine(\"postgresql://postgres:postgres@localhost/CPG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewrichtmyer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n"
     ]
    }
   ],
   "source": [
    "# run model and save to csv for all tables in postgreSQL database\n",
    "month_avg = monthlyEmotionAvg(filename=\"eucerin_eczema_cream.csv\",table=\"eucerin_eczema_cream\",\n",
    "                             engine=create_engine(\"postgresql://postgres:postgres@localhost/CPG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewrichtmyer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n"
     ]
    }
   ],
   "source": [
    "month_avg = monthlyEmotionAvg(\"eucerin_intensive_lotion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewrichtmyer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n"
     ]
    }
   ],
   "source": [
    "file_dict = {\"CeraVe_cream\": \"CeraVe_cream.csv\",\n",
    "             \"CeraVe_lotion\": \"CeraVe_lotion.csv\",\n",
    "             \"cerave_cream\": \"cerave_cream.csv\",\n",
    "             \"cerave_lotion\": \"cerave_lotion.csv\",\n",
    "             \"eucerin_adv_cream\": \"Eucerin_advanced_cream.csv\",\n",
    "             \"eucerin_eczema_cream\": \"Eucerin_eczema_cream.csv\"}\n",
    "\n",
    "for key in list(file_dict.keys()):\n",
    "    try:\n",
    "        filename = file_dict[key]\n",
    "        table = key\n",
    "        engine = create_engine(\"postgresql://postgres:postgres@localhost/CPG\")\n",
    "        month_avg = monthlyEmotionAvg(filename,table,engine)\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2017-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2017-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2018-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anger  anticipation  disgust  fear  joy  negative  positive  sadness  \\\n",
       "0    0.0           0.0      0.0   0.0  0.0       0.2       0.0      0.0   \n",
       "1    0.0           2.4      0.0   0.6  1.8       0.6       2.4      0.0   \n",
       "2    0.0           0.4      0.0   0.0  0.4       0.8       0.8      0.0   \n",
       "3    0.0           2.0      0.0   0.0  1.0       0.0       3.0      2.0   \n",
       "4    0.8           2.4      0.8   0.0  3.2       0.8       5.6      0.0   \n",
       "\n",
       "   surprise  trust       dates  \n",
       "0       0.0    0.0  2016-02-01  \n",
       "1       0.0    1.8  2017-07-01  \n",
       "2       0.0    1.6  2017-08-01  \n",
       "3       0.0    2.0  2017-11-01  \n",
       "4       0.8    4.8  2018-05-01  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"eucerin_intensive_lotion.csv\"\n",
    "name = \"/Users/matthewrichtmyer/Documents/Data Science Bootcamp/Project 2/CPG-Analysis/data/emotion_csv/\" + str(filename)\n",
    "month_avg.to_csv(name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = readData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>profile_name</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review</th>\n",
       "      <th>helpful</th>\n",
       "      <th>form</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>saics</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>This is not the same great product</td>\n",
       "      <td>Reviewed in the United States on November 23, ...</td>\n",
       "      <td>The bottle said it's the same great product, b...</td>\n",
       "      <td>88 people found this helpful</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>https://www.amazon.com/Eucerin-Intensive-Repai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Shadow</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Home Run</td>\n",
       "      <td>Reviewed in the United States on May 16, 2018</td>\n",
       "      <td>PERFECT!  Let me say that again.  PERFECT.  We...</td>\n",
       "      <td>31 people found this helpful</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>https://www.amazon.com/Eucerin-Intensive-Repai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>N. Keithley</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Great for dry skin!</td>\n",
       "      <td>Reviewed in the United States on July 3, 2017</td>\n",
       "      <td>I am a Texas woman who is not afraid to walk b...</td>\n",
       "      <td>38 people found this helpful</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>https://www.amazon.com/Eucerin-Intensive-Repai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Nilan</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>Great but leaves a sticky feeling</td>\n",
       "      <td>Reviewed in the United States on August 9, 2017</td>\n",
       "      <td>This is the richest formula, so its very heavy...</td>\n",
       "      <td>35 people found this helpful</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>https://www.amazon.com/Eucerin-Intensive-Repai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>jlfriddle2012</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Won't use anything but this</td>\n",
       "      <td>Reviewed in the United States on February 2, 2016</td>\n",
       "      <td>I've been using Eucerin lotion for 20+ years. ...</td>\n",
       "      <td>25 people found this helpful</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>https://www.amazon.com/Eucerin-Intensive-Repai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   profile_name               stars                               title  \\\n",
       "0   1          saics  1.0 out of 5 stars  This is not the same great product   \n",
       "1   2         Shadow  5.0 out of 5 stars                            Home Run   \n",
       "2   3    N. Keithley  5.0 out of 5 stars                 Great for dry skin!   \n",
       "3   4          Nilan  4.0 out of 5 stars   Great but leaves a sticky feeling   \n",
       "4   5  jlfriddle2012  5.0 out of 5 stars         Won't use anything but this   \n",
       "\n",
       "                                         review_date  \\\n",
       "0  Reviewed in the United States on November 23, ...   \n",
       "1      Reviewed in the United States on May 16, 2018   \n",
       "2      Reviewed in the United States on July 3, 2017   \n",
       "3    Reviewed in the United States on August 9, 2017   \n",
       "4  Reviewed in the United States on February 2, 2016   \n",
       "\n",
       "                                              review  \\\n",
       "0  The bottle said it's the same great product, b...   \n",
       "1  PERFECT!  Let me say that again.  PERFECT.  We...   \n",
       "2  I am a Texas woman who is not afraid to walk b...   \n",
       "3  This is the richest formula, so its very heavy...   \n",
       "4  I've been using Eucerin lotion for 20+ years. ...   \n",
       "\n",
       "                        helpful    form    brand  \\\n",
       "0  88 people found this helpful  Lotion  Eucerin   \n",
       "1  31 people found this helpful  Lotion  Eucerin   \n",
       "2  38 people found this helpful  Lotion  Eucerin   \n",
       "3  35 people found this helpful  Lotion  Eucerin   \n",
       "4  25 people found this helpful  Lotion  Eucerin   \n",
       "\n",
       "                               sku  \\\n",
       "0  Eucerin Intensive Repair Lotion   \n",
       "1  Eucerin Intensive Repair Lotion   \n",
       "2  Eucerin Intensive Repair Lotion   \n",
       "3  Eucerin Intensive Repair Lotion   \n",
       "4  Eucerin Intensive Repair Lotion   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.amazon.com/Eucerin-Intensive-Repai...  \n",
       "1  https://www.amazon.com/Eucerin-Intensive-Repai...  \n",
       "2  https://www.amazon.com/Eucerin-Intensive-Repai...  \n",
       "3  https://www.amazon.com/Eucerin-Intensive-Repai...  \n",
       "4  https://www.amazon.com/Eucerin-Intensive-Repai...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewrichtmyer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-c66e1b757f55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0memotion_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonthlyEmotionAvg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"eucerin_intensive_lotion.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-895316e2a8b2>\u001b[0m in \u001b[0;36mmonthlyEmotionAvg\u001b[0;34m(df, filename)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/matthewrichtmyer/Documents/Data Science Bootcamp/Project 2/CPG-Analysis/data/emotion_csv/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mmonth_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmonth_avg\u001b[0m \u001b[0;31m# this is just returning a dictionary, not list of dictionary which is needed for JS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "test_df, test_dict = read_transform()\n",
    "\n",
    "emotion_df = monthlyEmotionAvg(test_df,\"eucerin_intensive_lotion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1090 entries, 0 to 1089\n",
      "Data columns (total 13 columns):\n",
      "id              1090 non-null int64\n",
      "profile_name    1090 non-null object\n",
      "stars           1090 non-null float64\n",
      "title           1090 non-null object\n",
      "review_date     1090 non-null object\n",
      "review          1090 non-null object\n",
      "helpful         1090 non-null int64\n",
      "form            1090 non-null object\n",
      "brand           1090 non-null object\n",
      "sku             1090 non-null object\n",
      "url             1090 non-null object\n",
      "corr_date       1090 non-null datetime64[ns]\n",
      "word_count      1090 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(8)\n",
      "memory usage: 110.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = text_emotion(readData().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>profile_name</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review</th>\n",
       "      <th>helpful</th>\n",
       "      <th>form</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku</th>\n",
       "      <th>...</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>saics</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>This is not the same great product</td>\n",
       "      <td>Reviewed in the United States on November 23, ...</td>\n",
       "      <td>The bottle said it's the same great product, b...</td>\n",
       "      <td>88 people found this helpful</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Shadow</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Home Run</td>\n",
       "      <td>Reviewed in the United States on May 16, 2018</td>\n",
       "      <td>PERFECT!  Let me say that again.  PERFECT.  We...</td>\n",
       "      <td>31 people found this helpful</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>N. Keithley</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Great for dry skin!</td>\n",
       "      <td>Reviewed in the United States on July 3, 2017</td>\n",
       "      <td>I am a Texas woman who is not afraid to walk b...</td>\n",
       "      <td>38 people found this helpful</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Nilan</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>Great but leaves a sticky feeling</td>\n",
       "      <td>Reviewed in the United States on August 9, 2017</td>\n",
       "      <td>This is the richest formula, so its very heavy...</td>\n",
       "      <td>35 people found this helpful</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>jlfriddle2012</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Won't use anything but this</td>\n",
       "      <td>Reviewed in the United States on February 2, 2016</td>\n",
       "      <td>I've been using Eucerin lotion for 20+ years. ...</td>\n",
       "      <td>25 people found this helpful</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   profile_name               stars                               title  \\\n",
       "0   1          saics  1.0 out of 5 stars  This is not the same great product   \n",
       "1   2         Shadow  5.0 out of 5 stars                            Home Run   \n",
       "2   3    N. Keithley  5.0 out of 5 stars                 Great for dry skin!   \n",
       "3   4          Nilan  4.0 out of 5 stars   Great but leaves a sticky feeling   \n",
       "4   5  jlfriddle2012  5.0 out of 5 stars         Won't use anything but this   \n",
       "\n",
       "                                         review_date  \\\n",
       "0  Reviewed in the United States on November 23, ...   \n",
       "1      Reviewed in the United States on May 16, 2018   \n",
       "2      Reviewed in the United States on July 3, 2017   \n",
       "3    Reviewed in the United States on August 9, 2017   \n",
       "4  Reviewed in the United States on February 2, 2016   \n",
       "\n",
       "                                              review  \\\n",
       "0  The bottle said it's the same great product, b...   \n",
       "1  PERFECT!  Let me say that again.  PERFECT.  We...   \n",
       "2  I am a Texas woman who is not afraid to walk b...   \n",
       "3  This is the richest formula, so its very heavy...   \n",
       "4  I've been using Eucerin lotion for 20+ years. ...   \n",
       "\n",
       "                        helpful    form    brand  \\\n",
       "0  88 people found this helpful  Lotion  Eucerin   \n",
       "1  31 people found this helpful  Lotion  Eucerin   \n",
       "2  38 people found this helpful  Lotion  Eucerin   \n",
       "3  35 people found this helpful  Lotion  Eucerin   \n",
       "4  25 people found this helpful  Lotion  Eucerin   \n",
       "\n",
       "                               sku  ... anger  anticipation  disgust  fear  \\\n",
       "0  Eucerin Intensive Repair Lotion  ...     0             2        0     0   \n",
       "1  Eucerin Intensive Repair Lotion  ...     1             3        1     0   \n",
       "2  Eucerin Intensive Repair Lotion  ...     0             4        0     1   \n",
       "3  Eucerin Intensive Repair Lotion  ...     0             1        0     0   \n",
       "4  Eucerin Intensive Repair Lotion  ...     0             0        0     0   \n",
       "\n",
       "   joy  negative  positive  sadness  surprise  trust  \n",
       "0    1         0         3        2         0      2  \n",
       "1    4         1         7        0         1      6  \n",
       "2    3         1         4        0         0      3  \n",
       "3    1         2         2        0         0      4  \n",
       "4    0         1         0        0         0      0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewrichtmyer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n"
     ]
    }
   ],
   "source": [
    "test_df, test_dict = read_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>profile_name</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review</th>\n",
       "      <th>helpful</th>\n",
       "      <th>form</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku</th>\n",
       "      <th>url</th>\n",
       "      <th>corr_date</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>saics</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This is not the same great product</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>The bottle said it's the same great product, b...</td>\n",
       "      <td>88</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>https://www.amazon.com/Eucerin-Intensive-Repai...</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Shadow</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Home Run</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>PERFECT!  Let me say that again.  PERFECT.  We...</td>\n",
       "      <td>31</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>https://www.amazon.com/Eucerin-Intensive-Repai...</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>N. Keithley</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great for dry skin!</td>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>I am a Texas woman who is not afraid to walk b...</td>\n",
       "      <td>38</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>https://www.amazon.com/Eucerin-Intensive-Repai...</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Nilan</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great but leaves a sticky feeling</td>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>This is the richest formula, so its very heavy...</td>\n",
       "      <td>35</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>https://www.amazon.com/Eucerin-Intensive-Repai...</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>jlfriddle2012</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Won't use anything but this</td>\n",
       "      <td>2016-02-02</td>\n",
       "      <td>I've been using Eucerin lotion for 20+ years. ...</td>\n",
       "      <td>25</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>https://www.amazon.com/Eucerin-Intensive-Repai...</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   profile_name  stars                               title review_date  \\\n",
       "0   1          saics    1.0  This is not the same great product  2017-11-23   \n",
       "1   2         Shadow    5.0                            Home Run  2018-05-16   \n",
       "2   3    N. Keithley    5.0                 Great for dry skin!  2017-07-03   \n",
       "3   4          Nilan    4.0   Great but leaves a sticky feeling  2017-08-09   \n",
       "4   5  jlfriddle2012    5.0         Won't use anything but this  2016-02-02   \n",
       "\n",
       "                                              review  helpful    form  \\\n",
       "0  The bottle said it's the same great product, b...       88  Lotion   \n",
       "1  PERFECT!  Let me say that again.  PERFECT.  We...       31  Lotion   \n",
       "2  I am a Texas woman who is not afraid to walk b...       38  Lotion   \n",
       "3  This is the richest formula, so its very heavy...       35  Lotion   \n",
       "4  I've been using Eucerin lotion for 20+ years. ...       25  Lotion   \n",
       "\n",
       "     brand                              sku  \\\n",
       "0  Eucerin  Eucerin Intensive Repair Lotion   \n",
       "1  Eucerin  Eucerin Intensive Repair Lotion   \n",
       "2  Eucerin  Eucerin Intensive Repair Lotion   \n",
       "3  Eucerin  Eucerin Intensive Repair Lotion   \n",
       "4  Eucerin  Eucerin Intensive Repair Lotion   \n",
       "\n",
       "                                                 url  corr_date  word_count  \n",
       "0  https://www.amazon.com/Eucerin-Intensive-Repai... 2017-11-01          35  \n",
       "1  https://www.amazon.com/Eucerin-Intensive-Repai... 2018-05-01         193  \n",
       "2  https://www.amazon.com/Eucerin-Intensive-Repai... 2017-07-01         160  \n",
       "3  https://www.amazon.com/Eucerin-Intensive-Repai... 2017-08-01         124  \n",
       "4  https://www.amazon.com/Eucerin-Intensive-Repai... 2016-02-01         113  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_date': [Timestamp('2017-11-23 00:00:00'),\n",
       "  Timestamp('2018-05-16 00:00:00'),\n",
       "  Timestamp('2017-07-03 00:00:00'),\n",
       "  Timestamp('2017-08-09 00:00:00'),\n",
       "  Timestamp('2016-02-02 00:00:00')],\n",
       " 'gb_date': ['2016-02-01',\n",
       "  '2017-07-01',\n",
       "  '2017-08-01',\n",
       "  '2017-11-01',\n",
       "  '2018-05-01'],\n",
       " 'avg_monthly_rating': [5.0, 5.0, 4.0, 1.0, 5.0],\n",
       " 'histogram_rating_values': [1, 0, 0, 1, 3],\n",
       " 'histogram_rating_bins': [1, 2, 3, 4, 5, 6],\n",
       " 'max_upvoted_review': \"The bottle said it's the same great product, but it isn't.  This new product irritates my skin.  The old blue top didn't.  I love the blue top.\"}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_df = text_emotion(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>profile_name</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review</th>\n",
       "      <th>helpful</th>\n",
       "      <th>form</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku</th>\n",
       "      <th>...</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>saics</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This is not the same great product</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>The bottle said it's the same great product, b...</td>\n",
       "      <td>88</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Shadow</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Home Run</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>PERFECT!  Let me say that again.  PERFECT.  We...</td>\n",
       "      <td>31</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>N. Keithley</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great for dry skin!</td>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>I am a Texas woman who is not afraid to walk b...</td>\n",
       "      <td>38</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Nilan</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great but leaves a sticky feeling</td>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>This is the richest formula, so its very heavy...</td>\n",
       "      <td>35</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>jlfriddle2012</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Won't use anything but this</td>\n",
       "      <td>2016-02-02</td>\n",
       "      <td>I've been using Eucerin lotion for 20+ years. ...</td>\n",
       "      <td>25</td>\n",
       "      <td>Lotion</td>\n",
       "      <td>Eucerin</td>\n",
       "      <td>Eucerin Intensive Repair Lotion</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   profile_name  stars                               title review_date  \\\n",
       "0   1          saics    1.0  This is not the same great product  2017-11-23   \n",
       "1   2         Shadow    5.0                            Home Run  2018-05-16   \n",
       "2   3    N. Keithley    5.0                 Great for dry skin!  2017-07-03   \n",
       "3   4          Nilan    4.0   Great but leaves a sticky feeling  2017-08-09   \n",
       "4   5  jlfriddle2012    5.0         Won't use anything but this  2016-02-02   \n",
       "\n",
       "                                              review  helpful    form  \\\n",
       "0  The bottle said it's the same great product, b...       88  Lotion   \n",
       "1  PERFECT!  Let me say that again.  PERFECT.  We...       31  Lotion   \n",
       "2  I am a Texas woman who is not afraid to walk b...       38  Lotion   \n",
       "3  This is the richest formula, so its very heavy...       35  Lotion   \n",
       "4  I've been using Eucerin lotion for 20+ years. ...       25  Lotion   \n",
       "\n",
       "     brand                              sku  ... anger anticipation  disgust  \\\n",
       "0  Eucerin  Eucerin Intensive Repair Lotion  ...     0            2        0   \n",
       "1  Eucerin  Eucerin Intensive Repair Lotion  ...     1            3        1   \n",
       "2  Eucerin  Eucerin Intensive Repair Lotion  ...     0            4        0   \n",
       "3  Eucerin  Eucerin Intensive Repair Lotion  ...     0            1        0   \n",
       "4  Eucerin  Eucerin Intensive Repair Lotion  ...     0            0        0   \n",
       "\n",
       "   fear  joy  negative  positive  sadness  surprise  trust  \n",
       "0     0    1         0         3        2         0      2  \n",
       "1     0    4         1         7        0         1      6  \n",
       "2     1    3         1         4        0         0      3  \n",
       "3     0    1         2         2        0         0      4  \n",
       "4     0    0         1         0        0         0      0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = monthlyEmotionAvg(emotion_df,\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat dict into dataframe\n",
    "test2_df = pd.DataFrame(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2017-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2017-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2018-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anger  anticipation  disgust  fear  joy  negative  positive  sadness  \\\n",
       "0    0.0           0.0      0.0   0.0  0.0       0.4       0.0      0.0   \n",
       "1    0.0           4.8      0.0   1.2  3.6       1.2       4.8      0.0   \n",
       "2    0.0           0.8      0.0   0.0  0.8       1.6       1.6      0.0   \n",
       "3    0.0           4.0      0.0   0.0  2.0       0.0       6.0      4.0   \n",
       "4    1.6           4.8      1.6   0.0  6.4       1.6      11.2      0.0   \n",
       "\n",
       "   surprise  trust       dates  \n",
       "0       0.0    0.0  2016-02-01  \n",
       "1       0.0    3.6  2017-07-01  \n",
       "2       0.0    3.2  2017-08-01  \n",
       "3       0.0    4.0  2017-11-01  \n",
       "4       1.6    9.6  2018-05-01  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     name = \"/Users/matthewrichtmyer/Documents/Data Science Bootcamp/Project 2/CPG-Analysis/data/emotion_csv/\" + str(filename)\n",
    "    \n",
    "    \n",
    "#     month_avg.to_csv(name,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
